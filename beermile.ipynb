{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Beermile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "url_base = 'https://www.beermile.com/display/'\n",
    "max_event_id = 151381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Find which events are actually races\n",
    "is_event = 0\n",
    "not_event = 0\n",
    "\n",
    "\n",
    "# Look for all events by numerical ID\n",
    "for i in range(1, max_event_id):\n",
    "    # Website uses sequential \n",
    "    event = f'event_{i}'\n",
    "    url = f'{url_base}{event}'\n",
    "    result = requests.get(url)\n",
    "    page = urlopen(result.url).read()\n",
    "    a = bs(page, 'html.parser')\n",
    "    \n",
    "    event_type = False\n",
    "    if (a.title.string == 'Race Not Available'):\n",
    "        not_event += 1\n",
    "        with open('not_events.txt', 'a') as g:\n",
    "            g.write(f'{i}\\n')\n",
    "    else:\n",
    "        is_event += 1\n",
    "        event_type = True\n",
    "        with open('events.txt', 'a') as f:\n",
    "            f.write(f'{i}\\n')\n",
    "            \n",
    "    print(f'\\r #{i:06d} Events: {is_event:<6} - Not Events: {not_event:<6}', end='') \n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clean Data Into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def clean_soup_list(soup_list):\n",
    "    clean_soup_list = [s.text.strip() for s in soup_list]\n",
    "    return clean_soup_list\n",
    "\n",
    "def get_new_cols(headers, columns=[]):\n",
    "    '''\n",
    "    Use headers (from a table) Soup to find columns not already defined  \n",
    "    '''\n",
    "    new_columns = []\n",
    "    headers = clean_soup_list(headers)\n",
    "    for col in headers:\n",
    "        if col not in columns:\n",
    "            new_columns.append(col)\n",
    "    return new_columns\n",
    "\n",
    "def get_data_rows(event_rows):\n",
    "    data = []\n",
    "    is_header = True\n",
    "    for row in event_rows:\n",
    "        # Skip over first row (since it's the header)\n",
    "        if (is_header):\n",
    "            is_header = False\n",
    "        else:\n",
    "            cols = row.find_all('td')\n",
    "            # TODO: Determine how to \"clean\" string\n",
    "            cols = [ele.text.strip() for ele in cols]\n",
    "            row = [ele for ele in cols]\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "def add_soup_to_df(events_soup, df):\n",
    "    '''\n",
    "    Add data (and potentially new columns) from Soup to df\n",
    "    '''\n",
    "    # Add new columns to df\n",
    "    columns = df.columns\n",
    "    headers = events_soup.find_all('tr')[0].find_all('td')\n",
    "    new_columns = get_new_cols(headers, columns)\n",
    "    for c in new_columns:\n",
    "        df[c] = np.nan\n",
    "    # Add data to df\n",
    "    data_rows = events_soup.find_all('tr')\n",
    "    new = get_data_rows(data_rows)\n",
    "    df = df.append(\n",
    "        pd.DataFrame(new, columns=clean_soup_list(headers)),\n",
    "        sort=False\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Iterate through events list to get data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "url_event_base = 'https://www.beermile.com/display/event_'\n",
    "cols = []\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for n_event in open('events.txt'):\n",
    "    url = f'{url_event_base}{n_event}'\n",
    "    page = urlopen(url).read()\n",
    "    soup = bs(page, 'html.parser')\n",
    "    \n",
    "    df = add_soup_to_df(soup,df)\n",
    "    # TEST: Only go through 5 results\n",
    "    count += 1\n",
    "    if count >5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Display DataFrame created\n",
    "display(df.head())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Process data parallel (experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import urlopen\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events = [n for n in open('events.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_event(event_id):\n",
    "    count = 0\n",
    "    url_event_base = 'https://www.beermile.com/display/event_'\n",
    "    cols = []\n",
    "    df = pd.DataFrame()\n",
    "    url = f'{url_event_base}{event_id.strip()}'\n",
    "    \n",
    "    page = urlopen(url).read()\n",
    "    soup = bs(page, 'html.parser')\n",
    "\n",
    "    # Data to dataframe\n",
    "    df = add_soup_to_df(soup,df)\n",
    "    # Related info added for each entry\n",
    "    df['URL'] = url\n",
    "    # If nothing available, at least save the URL\n",
    "    if(len(df.index) == 0):\n",
    "        df = pd.DataFrame({\"URL\": [url]})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with ProcessPoolExecutor(max_workers=16) as executor:\n",
    "    start = time.time()\n",
    "    # Clean data for each event\n",
    "    futures = [executor.submit(get_df_from_event, url) for url in all_events]\n",
    "    results = []\n",
    "    for result in as_completed(futures):\n",
    "        results.append(result)\n",
    "    end = time.time()\n",
    "    print(\"Time Taken: {:.6f}s\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
