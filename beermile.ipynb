{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Beermile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://www.beermile.com/display/'\n",
    "max_event_id = 151381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #022809 Events: 2375   - Not Events: 20024 "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Find which events are actually races\n",
    "is_event = 0\n",
    "not_event = 0\n",
    "\n",
    "\n",
    "# Look for all events by numerical ID\n",
    "for i in range(1+410, max_event_id):\n",
    "    # Website uses sequential \n",
    "    event = f'event_{i}'\n",
    "    url = f'{url_base}{event}'\n",
    "    result = requests.get(url)\n",
    "    page = urlopen(result.url).read()\n",
    "    a = bs(page, 'html.parser')\n",
    "    \n",
    "    eventType = False\n",
    "    if (a.title.string == 'Race Not Available'):\n",
    "        not_event += 1\n",
    "        with open('not_events.txt', 'a') as g:\n",
    "            g.write(f'{i}\\n')\n",
    "    else:\n",
    "        is_event += 1\n",
    "        eventType = True\n",
    "        with open('events.txt', 'a') as f:\n",
    "            f.write(f'{i}\\n')\n",
    "            \n",
    "    print(f'\\r #{i:06d} Events: {is_event:<6} - Not Events: {not_event:<6}', end='') \n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data Into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfFromTable(table_soup):\n",
    "    is_header = True\n",
    "    pd_cols = []\n",
    "    df = None\n",
    "    \n",
    "    rows = table_soup.find_all('tr')\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        # TODO: Determine how to \"clean\" string\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        row = [ele for ele in cols if ele]\n",
    "        # First row will be the names for the columns\n",
    "        if (is_header):\n",
    "            is_header = False\n",
    "            # Add in place columns\n",
    "            pd_cols = ['Place'] + row\n",
    "            df = pd.DataFrame(columns=pd_cols)\n",
    "        else:\n",
    "            # Associate columns with values before insertion\n",
    "            small_dict = {}\n",
    "            for i in range(len(row)):\n",
    "                small_dict[pd_cols[i]] = row[i]\n",
    "            df = df.append(small_dict, ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
